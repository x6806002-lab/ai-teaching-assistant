import csv
import pandas as pd
import networkx as nx
import os
from typing import Dict, List, Tuple, Optional


class DataLoader:
    """ç»Ÿä¸€æ•°æ®åŠ è½½å™¨"""

    def __init__(self):
        self.data = {}
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•ä½œä¸ºåŸºå‡†ç›®å½•
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        print(f"ğŸ“ æ•°æ®åŠ è½½å™¨åŸºå‡†ç›®å½•: {self.base_dir}")

    def _get_file_path(self, filename: str) -> str:
        """è·å–æ–‡ä»¶çš„å®Œæ•´è·¯å¾„"""
        # åœ¨è„šæœ¬æ‰€åœ¨ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶
        file_path = os.path.join(self.base_dir, filename)
        print(f"ğŸ” æŸ¥æ‰¾æ–‡ä»¶: {file_path}")
        return file_path

    def load_csv_with_encoding(self, file_path: str, encodings: List[str] = None) -> List[Dict]:
        """å¸¦ç¼–ç æ£€æµ‹çš„CSVåŠ è½½"""
        if encodings is None:
            encodings = ['utf-8-sig', 'gbk', 'utf-8']

        # è·å–å®Œæ•´è·¯å¾„
        full_path = self._get_file_path(file_path)

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(full_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
            return []

        print(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {full_path}")

        for encoding in encodings:
            try:
                with open(full_path, 'r', encoding=encoding) as f:
                    reader = csv.DictReader(f)
                    data = list(reader)
                    print(f"âœ… {file_path} åŠ è½½æˆåŠŸ ({encoding}): {len(data)} æ¡è®°å½•")
                    return data
            except UnicodeDecodeError:
                continue
            except Exception as e:
                print(f"âŒ {file_path} åŠ è½½å¤±è´¥: {e}")
                return []

        print(f"âŒ {file_path} æ‰€æœ‰ç¼–ç å°è¯•å¤±è´¥")
        return []

    def load_keyword_mapping(self, file_path: str = 'keyword_mapping.csv') -> Dict[str, Dict]:
        """åŠ è½½å…³é”®è¯æ˜ å°„"""
        data = self.load_csv_with_encoding(file_path)
        mapping = {}

        for row in data:
            keyword = row['å…³é”®è¯'].strip()
            mapping[keyword] = {
                'indicator_code': row['æŒ‡æ ‡ç¼–ç '],
                'weight': float(row['æƒé‡']),
                'parent_indicator': row['çˆ¶çº§æŒ‡æ ‡']
            }

        print(f"âœ… å…³é”®è¯æ˜ å°„åŠ è½½: {len(mapping)} ä¸ªæ˜ å°„")
        return mapping

    def load_weight_data(self, file_path: str = 'weight.csv') -> pd.DataFrame:
        """åŠ è½½æƒé‡æ•°æ®"""
        try:
            full_path = self._get_file_path(file_path)
            if not os.path.exists(full_path):
                print(f"âŒ æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {full_path}")
                return pd.DataFrame()

            df = pd.read_csv(full_path, encoding='utf-8-sig')
            # æ¸…ç†åˆ—å
            df.columns = df.columns.str.strip()
            print(f"âœ… æƒé‡æ•°æ®åŠ è½½: {len(df)} æ¡è®°å½•")
            return df
        except Exception as e:
            print(f"âŒ æƒé‡æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return pd.DataFrame()

    def load_teaching_corpus(self, file_path: str = 'Teaching_corpus.csv') -> List[Dict]:
        """åŠ è½½æ•™å­¦è¯­æ–™åº“"""
        data = self.load_csv_with_encoding(file_path)
        corpus = []

        for row in data:
            # å¤„ç†å…³é”®è¯ï¼ˆå¯èƒ½åŒ…å«å¤šä¸ªå…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ï¼‰
            keywords = [k.strip() for k in row['å…³é”®è¯'].split(',')]

            corpus.append({
                'knowledge_domain': row['çŸ¥è¯†é¢†åŸŸ'].strip(),
                'keywords': keywords,
                'description': row['è¯¦ç»†æè¿°'].strip()
            })

        print(f"âœ… æ•™å­¦è¯­æ–™åº“åŠ è½½: {len(corpus)} æ¡è®°å½•")
        return corpus

    def load_expert_knowledge(self, file_path: str = 'expert_knowledge.csv') -> nx.DiGraph:
        """åŠ è½½ä¸“å®¶çŸ¥è¯†åº“å¹¶æ„å»ºçŸ¥è¯†å›¾è°±"""
        data = self.load_csv_with_encoding(file_path)
        G = nx.DiGraph()

        for row in data:
            head = row['head'].strip()
            tail = row['tail'].strip()
            relation = row['relation'].strip()

            # æ·»åŠ èŠ‚ç‚¹
            if head not in G:
                G.add_node(head, type='concept')
            if tail not in G:
                G.add_node(tail, type='concept')

            # æ·»åŠ è¾¹
            G.add_edge(head, tail, relation=relation)

        print(f"âœ… çŸ¥è¯†å›¾è°±æ„å»º: {G.number_of_nodes()} èŠ‚ç‚¹, {G.number_of_edges()} è¾¹")
        return G

    def load_all_data(self) -> Dict:
        """åŠ è½½æ‰€æœ‰æ•°æ®"""
        print("ğŸš€ å¼€å§‹åŠ è½½æ‰€æœ‰æ•°æ®æ–‡ä»¶...")
        print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        print(f"ğŸ“ è„šæœ¬æ‰€åœ¨ç›®å½•: {self.base_dir}")

        # åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶
        print("ğŸ“‹ å½“å‰ç›®å½•æ–‡ä»¶åˆ—è¡¨:")
        for file in os.listdir(self.base_dir):
            if file.endswith('.csv'):
                print(f"   - {file}")

        self.data = {
            'keyword_mapping': self.load_keyword_mapping(),
            'weight_df': self.load_weight_data(),
            'teaching_corpus': self.load_teaching_corpus(),
            'knowledge_graph': self.load_expert_knowledge()
        }

        # æ„å»ºæƒé‡æ˜ å°„å­—å…¸
        weight_mapping = {}
        if not self.data['weight_df'].empty:
            for _, row in self.data['weight_df'].iterrows():
                weight_mapping[row['æŒ‡æ ‡ç¼–ç ']] = {
                    'absolute_weight': row['ç»å¯¹æƒé‡'],
                    'relative_weight': row['ç›¸å¯¹æƒé‡'],
                    'name': row['æŒ‡æ ‡åç§°'],
                    'level': row['å±‚çº§']
                }

        self.data['weight_mapping'] = weight_mapping

        print("âœ… æ‰€æœ‰æ•°æ®åŠ è½½å®Œæˆï¼")
        return self.data


# å…¨å±€æ•°æ®åŠ è½½å™¨å®ä¾‹
data_loader = DataLoader()


def load_all_data():
    """å…¨å±€æ•°æ®åŠ è½½å‡½æ•°"""
    return data_loader.load_all_data()
